{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is to classify names as male/female using different approaches, including neural networks and bayes classifier. Data is split between 2 files and is contained as lists. The task is completed with https://github.com/Bravo111"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import pandas as pd\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Length of 'female': 5001 \n",
      "\n",
      "########################### \n",
      "Female:\n",
      "\n",
      "0    Abagael\n",
      "1    Abagail\n",
      "2       Abbe\n",
      "3      Abbey\n",
      "4       Abbi\n",
      "5      Abbie\n",
      "6       Abby\n",
      "Name: name, dtype: object\n",
      "###########################\n",
      "\n",
      "\n",
      "Length of 'male': 2943 \n",
      "\n",
      "########################### \n",
      "Male:\n",
      "\n",
      "0     Aamir\n",
      "1     Aaron\n",
      "2     Abbey\n",
      "3     Abbie\n",
      "4     Abbot\n",
      "5    Abbott\n",
      "6      Abby\n",
      "Name: name, dtype: object\n",
      "###########################\n"
     ]
    }
   ],
   "source": [
    "df_f = pd.read_csv('data/female.txt', names=['name']).name\n",
    "df_m = pd.read_csv('data/male.txt', names=['name']).name\n",
    "\n",
    "print(\"\\nLength of 'female':\", len(df_f), '\\n')\n",
    "\n",
    "\n",
    "print('#'*27, '\\nFemale:\\n')\n",
    "print(df_f.head(7))\n",
    "print('#'*27)\n",
    "print(\"\\n\\nLength of 'male':\", len(df_m), '\\n')\n",
    "print('#'*27, '\\nMale:\\n')\n",
    "print(df_m.head(7))\n",
    "print('#'*27)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete ambigous names male and female at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " New length of 'female': 4636\n",
      "\n",
      " New length of 'male': 2578\n"
     ]
    }
   ],
   "source": [
    "# Delete intersections:\n",
    "# using ~ to return only the rows you in df_f which are not df_test\n",
    "df_f_clean = df_f[~df_f.isin(df_m)].reset_index(drop=True)\n",
    "df_m_clean = df_m[~df_m.isin(df_f)].reset_index(drop=True)\n",
    "\n",
    "print(\"\\n New length of 'female':\", len(df_f_clean))\n",
    "print(\"\\n New length of 'male':\", len(df_m_clean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store data in a single dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aamir</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aaron</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abagael</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abagail</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abbe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abbi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Abbot</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  sex\n",
       "0    Aamir    0\n",
       "1    Aaron    0\n",
       "2  Abagael    1\n",
       "3  Abagail    1\n",
       "4     Abbe    1\n",
       "5     Abbi    1\n",
       "6    Abbot    0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_f_clean = pd.DataFrame(df_f_clean)\n",
    "df_f_clean['sex'] = 1\n",
    "df_m_clean = pd.DataFrame(df_m_clean)\n",
    "df_m_clean['sex'] = 0\n",
    "\n",
    "df = pd.concat([df_f_clean, df_m_clean])\n",
    "df = df.sort_values('name').reset_index(drop=True)\n",
    "df.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data is derived as 20% of names for each letter in an alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test percentage: 0.19725533684502355\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(1789)\n",
    "\n",
    "train = pd.DataFrame()\n",
    "test = pd.DataFrame()\n",
    "\n",
    "letters = 'A B C D E F G H I J K L M N O P Q R S T U V W X Y Z'.split()\n",
    "\n",
    "for letter in letters:\n",
    "    names_starts_with_letter = df[ df.name.str.startswith(letter) ]\n",
    "    msk = np.random.rand( len(names_starts_with_letter) ) < 0.80\n",
    "    train = pd.concat([train, df[ df.name.str.startswith(letter) ][msk]])\n",
    "    test = pd.concat([test, df[ df.name.str.startswith(letter) ][~msk]])\n",
    "\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n",
    "\n",
    "print('\\nTest percentage:', (len(test)/len(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Symbolic n-grams for each name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.util import ngrams\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def symbol_ngram(test, train, n=2):\n",
    "    #################################### Test\n",
    "    test_n = pd.DataFrame()\n",
    "    t0 = time()\n",
    "\n",
    "    for i in tqdm(range(len(test['name']))):\n",
    "        name = test['name'][i]\n",
    "        \n",
    "        string_ngrams = ngrams(name, n=n)\n",
    "        sex = int(test[test['name'] == name]['sex'])\n",
    "        \n",
    "        for ngram in string_ngrams: \n",
    "            ngram_sex = pd.DataFrame([[''.join(ngram), sex]], columns=['n={}'.format(n), 'sex'])\n",
    "            test_n = pd.concat([test_n, ngram_sex])\n",
    "    \n",
    "    test_n = test_n.reset_index(drop=True)\n",
    "    \n",
    "    t_test = time() - t0\n",
    "    print(\"\\nPreprocessing time (test): %0.1fm\" % (t_test/60))\n",
    "    print('\\n', '#'*12, '\\n', test_n.head(7))\n",
    "    print('#'*12)\n",
    "    #################################### Test\n",
    "    \n",
    "    ############################# Train\n",
    "    train_n = pd.DataFrame()\n",
    "    t1 = time()\n",
    "    \n",
    "    for i in tqdm(range(len(train['name']))):\n",
    "        name = train['name'][i]\n",
    "        \n",
    "        string_ngrams = ngrams(name, n=n)\n",
    "        sex = int(train[train['name'] == name]['sex'])\n",
    "        \n",
    "        for ngram in string_ngrams: \n",
    "            ngram_sex = pd.DataFrame([[''.join(ngram), sex]], columns=['n={}'.format(n), 'sex'])\n",
    "            train_n = pd.concat([train_n, ngram_sex])\n",
    "\n",
    "    train_n = train_n.reset_index(drop=True)\n",
    "    \n",
    "    t_train = time() - t1\n",
    "    print(\"\\nPreprocessing time (train): %0.1fm\" % (t_train/60))\n",
    "    print('\\n', '#'*12, '\\n', train_n.head(7))\n",
    "    print('#'*12)\n",
    "    ############################# Train\n",
    "    \n",
    "    print(\"\\n\\nTotal preprocessing time: %0.1fm\" % ((t_test + t_train)/60))\n",
    "    \n",
    "    return test_n, train_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1423/1423 [00:09<00:00, 142.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing time (test): 0.2m\n",
      "\n",
      " ############ \n",
      "   n=2  sex\n",
      "0  Ab    1\n",
      "1  bb    1\n",
      "2  be    1\n",
      "3  Ab    1\n",
      "4  bb    1\n",
      "5  bi    1\n",
      "6  Ab    0\n",
      "############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 5791/5791 [00:51<00:00, 112.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing time (train): 0.9m\n",
      "\n",
      " ############ \n",
      "   n=2  sex\n",
      "0  Aa    0\n",
      "1  am    0\n",
      "2  mi    0\n",
      "3  ir    0\n",
      "4  Aa    0\n",
      "5  ar    0\n",
      "6  ro    0\n",
      "############\n",
      "\n",
      "\n",
      "Total preprocessing time: 1.0m\n"
     ]
    }
   ],
   "source": [
    "test_n2, train_n2 = symbol_ngram(test, train, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1423/1423 [00:19<00:00, 73.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing time (test): 0.3m\n",
      "\n",
      " ############ \n",
      "    n=3  sex\n",
      "0  Abb    1\n",
      "1  bbe    1\n",
      "2  Abb    1\n",
      "3  bbi    1\n",
      "4  Abb    0\n",
      "5  bbo    0\n",
      "6  bot    0\n",
      "############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5791/5791 [01:22<00:00, 70.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing time (train): 1.4m\n",
      "\n",
      " ############ \n",
      "    n=3  sex\n",
      "0  Aam    0\n",
      "1  ami    0\n",
      "2  mir    0\n",
      "3  Aar    0\n",
      "4  aro    0\n",
      "5  ron    0\n",
      "6  Aba    1\n",
      "############\n",
      "\n",
      "\n",
      "Total preprocessing time: 1.7m\n"
     ]
    }
   ],
   "source": [
    "test_n3, train_n3 = symbol_ngram(test, train, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Four-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1423/1423 [00:19<00:00, 71.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing time (test): 0.3m\n",
      "\n",
      " ############ \n",
      "     n=4  sex\n",
      "0  Abbe    1\n",
      "1  Abbi    1\n",
      "2  Abbo    0\n",
      "3  bbot    0\n",
      "4  Adah    1\n",
      "5  Adel    1\n",
      "6  dela    1\n",
      "############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5791/5791 [01:32<00:00, 62.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing time (train): 1.5m\n",
      "\n",
      " ############ \n",
      "     n=4  sex\n",
      "0  Aami    0\n",
      "1  amir    0\n",
      "2  Aaro    0\n",
      "3  aron    0\n",
      "4  Abag    1\n",
      "5  baga    1\n",
      "6  agae    1\n",
      "############\n",
      "\n",
      "\n",
      "Total preprocessing time: 1.9m\n"
     ]
    }
   ],
   "source": [
    "test_n4, train_n4 = symbol_ngram(test, train, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes for names classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F-score basic theory:\n",
    "\n",
    "It is therefore conventional to employ a different set of measures for search tasks, based on the number of items in each of the four categories shown in 3.1:\n",
    "\n",
    "* True positives are relevant items that we correctly identified as relevant.\n",
    "* True negatives are irrelevant items that we correctly identified as irrelevant.\n",
    "* False positives (or Type I errors) are irrelevant items that we incorrectly identified as relevant.\n",
    "* False negatives (or Type II errors) are relevant items that we incorrectly identified as irrelevant.\n",
    "\n",
    "Given these four numbers, we can define the following metrics:\n",
    "\n",
    "* Precision, which indicates how many of the items that we identified were relevant, is TP/(TP+FP).\n",
    "* Recall, which indicates how many of the relevant items that we identified, is TP/(TP+FN).\n",
    "* The F-Measure (or F-Score), which combines the precision and recall to give a single score, is defined to be the harmonic mean of the precision and recall: (2 × Precision × Recall) / (Precision + Recall)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk import NaiveBayesClassifier\n",
    "from nltk.classify import accuracy\n",
    "from nltk.metrics import f_measure\n",
    "import collections\n",
    "\n",
    "def classication_and_results(test_ngram, train_ngram):\n",
    "    # Feature extractor function.\n",
    "    def gender_features(word):\n",
    "        return {'ngram': word}\n",
    "\n",
    "    # Extract features\n",
    "    train_featuresets = [(gender_features(n), sex) for index, (n, sex) in train_ngram.iterrows()]\n",
    "    test_featuresets = [(gender_features(n), sex) for index, (n, sex) in test_ngram.iterrows()]\n",
    "\n",
    "    # Train model\n",
    "    classifier = NaiveBayesClassifier.train(train_featuresets)\n",
    "    \n",
    "    # Check the accuracy\n",
    "    print('\\nAccuracy of Naive Bayes:', accuracy(classifier, test_featuresets))\n",
    "    \n",
    "    # F-Measure\n",
    "    refsets = collections.defaultdict(set)\n",
    "    testsets = collections.defaultdict(set)\n",
    "    for i, (feats, label) in enumerate(test_featuresets):\n",
    "        refsets[label].add(i)\n",
    "        observed = classifier.classify(feats)\n",
    "        testsets[observed].add(i)\n",
    "\n",
    "\n",
    "    print('\\nFemale F-measure:', f_measure(refsets[1], testsets[1]))\n",
    "    print('  Male F-measure:', f_measure(refsets[0], testsets[0]))\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of Naive Bayes: 0.681749206787143\n",
      "\n",
      "Female F-measure: 0.780724265754206\n",
      "  Male F-measure: 0.4199145084234347\n"
     ]
    }
   ],
   "source": [
    "classifier_n2 = classication_and_results(test_n2, train_n2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of Naive Bayes: 0.7366975626501888\n",
      "\n",
      "Female F-measure: 0.8142857142857143\n",
      "  Male F-measure: 0.5477594339622641\n"
     ]
    }
   ],
   "source": [
    "classifier_n3 = classication_and_results(test_n3, train_n3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Four-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy of Naive Bayes: 0.7507943713118475\n",
      "\n",
      "Female F-measure: 0.8289186662511686\n",
      "  Male F-measure: 0.5413533834586466\n"
     ]
    }
   ],
   "source": [
    "classifier_n4 = classication_and_results(test_n4, train_n4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1423/1423 [00:07<00:00, 191.05it/s]\n",
      "  0%|          | 14/5791 [00:00<00:44, 130.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing time (test): 0.1m\n",
      "\n",
      " ############ \n",
      "      n=5  sex\n",
      "0  Abbot    0\n",
      "1  Adela    1\n",
      "2  delai    1\n",
      "3  elaid    1\n",
      "4  laide    1\n",
      "5  Adeli    1\n",
      "6  delin    1\n",
      "############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5791/5791 [00:35<00:00, 161.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing time (train): 0.6m\n",
      "\n",
      " ############ \n",
      "      n=5  sex\n",
      "0  Aamir    0\n",
      "1  Aaron    0\n",
      "2  Abaga    1\n",
      "3  bagae    1\n",
      "4  agael    1\n",
      "5  Abaga    1\n",
      "6  bagai    1\n",
      "############\n",
      "\n",
      "\n",
      "Total preprocessing time: 0.7m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_n5, train_n5 = symbol_ngram(test, train, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "The tendency is that the bigger 'n' for n-gram, the less F-score for male names. The assumption is that male names are shorter and have less characters than names for women. Also, the results may be related to initial data sizes of men's and women's names (5001 vs 2943). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprosessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a', 's', 'v', 'z', ' ', 'i', 'w', 'g', 'k', 'd', 'r', \"'\", 'q', 'o', 'f', 'm', 'x', 'b', 'u', 'c', 'l', 'n', 'e', 't', 'p', '-', 'y', 'h', 'j'}\n"
     ]
    }
   ],
   "source": [
    "test.name = test.name.str.lower()\n",
    "train.name = train.name.str.lower()\n",
    "\n",
    "chars = set(  \"\".join(list(test.name)) + \"\".join(list(train.name))  )\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Custom sort to rearrange order of letters and symbols\n",
    "def custom_sort(sorted_list):\n",
    "    not_letters = []\n",
    "    for char in sorted_list:\n",
    "        if not char.isalpha():\n",
    "            sorted_list.remove(char)\n",
    "            not_letters.append(char)\n",
    "    sorted_list = sorted_list + not_letters  \n",
    "    return sorted_list   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Dictionaries of characters with indices\n",
    "chars = custom_sort(sorted(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "maxlen = len(max(list(train.name) + list(test.name), key=len))\n",
    "X_train = np.zeros((train.shape[0] , maxlen, len(chars) ))\n",
    "y_train = np.zeros((train.shape[0] , 2 ))\n",
    "X_test = np.zeros((test.shape[0] , maxlen, len(chars) ))\n",
    "y_test = np.zeros((test.shape[0] , 2 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vectorization of train and test data\n",
    "\n",
    "for name in train.name:\n",
    "    word = train[train['name'] == name]\n",
    "    id_ = word.index.tolist()[0]\n",
    "    for t, char in enumerate(word['name'].any()):\n",
    "        X_train[id_, t, char_indices[char]] = 1\n",
    "    if word['sex'].any() == 0:\n",
    "        y_train[id_, 0] = 1\n",
    "    else:\n",
    "        y_train[id_, 1] = 1\n",
    "        \n",
    "             \n",
    "for name in test.name:\n",
    "    word = test[test['name'] == name]\n",
    "    id_ = word.index.tolist()[0]\n",
    "    for t, char in enumerate(word['name'].any()):\n",
    "        X_test[id_, t, char_indices[char]] = 1\n",
    "    if word['sex'].any() == 0:\n",
    "        y_test[id_, 0] = 1\n",
    "    else:\n",
    "        y_test[id_, 1] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from sklearn.metrics import f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 512 nodes, 0.2 dropout, 32 batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5791/5791 [==============================] - 124s - loss: 0.6966   \n",
      "Epoch 2/10\n",
      "5791/5791 [==============================] - 122s - loss: 0.6598   \n",
      "Epoch 3/10\n",
      "5791/5791 [==============================] - 124s - loss: 0.6495   \n",
      "Epoch 4/10\n",
      "5791/5791 [==============================] - 123s - loss: 0.6416   \n",
      "Epoch 5/10\n",
      "5791/5791 [==============================] - 125s - loss: 0.6315   \n",
      "Epoch 6/10\n",
      "5791/5791 [==============================] - 124s - loss: 0.6326   \n",
      "Epoch 7/10\n",
      "5791/5791 [==============================] - 125s - loss: 0.6285   \n",
      "Epoch 8/10\n",
      "5791/5791 [==============================] - 123s - loss: 0.6310   \n",
      "Epoch 9/10\n",
      "5791/5791 [==============================] - 135s - loss: 0.6298   \n",
      "Epoch 10/10\n",
      "5791/5791 [==============================] - 159s - loss: 0.6323   \n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(512, return_sequences=True, input_shape=(len(max(train.name, key=len)), len(chars))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(512, return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "model.fit(X_train, y_train, batch_size=32)\n",
    "model.save_weights('my_model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is  0.645115952214\n",
      "F score is  0.776053215078\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict_classes(X_test)\n",
    "print(\"Accuracy is \", accuracy_score(test.sex, predicted))\n",
    "print(\"F score is \", f1_score(test.sex, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 128 nodes, 0.4 dropout, 32 batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5791/5791 [==============================] - 43s - loss: 0.5322    \n",
      "Epoch 2/10\n",
      "5791/5791 [==============================] - 39s - loss: 0.4707    \n",
      "Epoch 3/10\n",
      "5791/5791 [==============================] - 39s - loss: 0.4489    \n",
      "Epoch 4/10\n",
      "5791/5791 [==============================] - 40s - loss: 0.4254    \n",
      "Epoch 5/10\n",
      "5791/5791 [==============================] - 41s - loss: 0.4113    \n",
      "Epoch 6/10\n",
      "5791/5791 [==============================] - 38s - loss: 0.3934    \n",
      "Epoch 7/10\n",
      "5791/5791 [==============================] - 38s - loss: 0.3769    \n",
      "Epoch 8/10\n",
      "5791/5791 [==============================] - 38s - loss: 0.3657    \n",
      "Epoch 9/10\n",
      "5791/5791 [==============================] - 38s - loss: 0.3507    \n",
      "Epoch 10/10\n",
      "5791/5791 [==============================] - 38s - loss: 0.3367    \n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "model.fit(X_train, y_train, batch_size=32)\n",
    "model.save_weights('128_04_128_04.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1408/1423 [============================>.] - ETA: 0s\n",
      "Accuracy is  0.815179198876\n",
      "F score is  0.861797162375\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict_classes(X_test)\n",
    "print()\n",
    "print(\"Accuracy is \", accuracy_score(test.sex, predicted))\n",
    "print(\"F score is \", f1_score(test.sex, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 256 nodes, 0.4 dropout, 16 batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5791/5791 [==============================] - 120s - loss: 0.6427   \n",
      "Epoch 2/10\n",
      "5791/5791 [==============================] - 117s - loss: 0.6120   \n",
      "Epoch 3/10\n",
      "5791/5791 [==============================] - 119s - loss: 0.5810   \n",
      "Epoch 4/10\n",
      "5791/5791 [==============================] - 117s - loss: 0.5598   \n",
      "Epoch 5/10\n",
      "5791/5791 [==============================] - 118s - loss: 0.5320   \n",
      "Epoch 6/10\n",
      "5791/5791 [==============================] - 118s - loss: 0.5138   \n",
      "Epoch 7/10\n",
      "5791/5791 [==============================] - 118s - loss: 0.4933   \n",
      "Epoch 8/10\n",
      "5791/5791 [==============================] - 118s - loss: 0.4764   \n",
      "Epoch 9/10\n",
      "5791/5791 [==============================] - 118s - loss: 0.4602   \n",
      "Epoch 10/10\n",
      "5791/5791 [==============================] - 118s - loss: 0.4394   \n",
      "1423/1423 [==============================] - 8s     \n",
      "\n",
      "Accuracy is  0.801124385102\n",
      "F score is  0.845439650464\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(256, return_sequences=True, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(LSTM(256, return_sequences=False))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "model.fit(X_train, y_train, batch_size=16)\n",
    "model.save_weights('256_04_256_04_batch16.h5')\n",
    "predicted = model.predict_classes(X_test)\n",
    "print()\n",
    "print(\"Accuracy is \", accuracy_score(test.sex, predicted))\n",
    "print(\"F score is \", f1_score(test.sex, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 128 nodes, 0.4 dropout, 16 batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5791/5791 [==============================] - 55s - loss: 0.5309    \n",
      "Epoch 2/10\n",
      "5791/5791 [==============================] - 50s - loss: 0.4028    \n",
      "Epoch 7/10\n",
      "5791/5791 [==============================] - 48s - loss: 0.3920    \n",
      "Epoch 8/10\n",
      "5791/5791 [==============================] - 48s - loss: 0.3781    \n",
      "Epoch 9/10\n",
      "5791/5791 [==============================] - 48s - loss: 0.3624    \n",
      "Epoch 10/10\n",
      "5791/5791 [==============================] - 47s - loss: 0.3411    \n",
      "1423/1423 [==============================] - 3s     \n",
      "\n",
      "Accuracy is  0.831342234715\n",
      "F score is  0.865470852018\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "model.fit(X_train, y_train, batch_size=16)\n",
    "model.save_weights('128_04_128_04_batch16.h5')\n",
    "predicted = model.predict_classes(X_test)\n",
    "print()\n",
    "print(\"Accuracy is \", accuracy_score(test.sex, predicted))\n",
    "print(\"F score is \", f1_score(test.sex, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 64 nodes, 0.4 dropout, 32 batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5791/5791 [==============================] - 25s - loss: 0.5374    \n",
      "Epoch 2/10\n",
      "5791/5791 [==============================] - 20s - loss: 0.4745    \n",
      "Epoch 3/10\n",
      "5791/5791 [==============================] - 19s - loss: 0.4503    \n",
      "Epoch 4/10\n",
      "5791/5791 [==============================] - 19s - loss: 0.4351    \n",
      "Epoch 5/10\n",
      "5791/5791 [==============================] - 19s - loss: 0.4155    \n",
      "Epoch 6/10\n",
      "5791/5791 [==============================] - 19s - loss: 0.3997    \n",
      "Epoch 7/10\n",
      "5791/5791 [==============================] - 21s - loss: 0.3865    \n",
      "Epoch 8/10\n",
      "5791/5791 [==============================] - 21s - loss: 0.3756    \n",
      "Epoch 9/10\n",
      "5791/5791 [==============================] - 21s - loss: 0.3628    \n",
      "Epoch 10/10\n",
      "5791/5791 [==============================] - 20s - loss: 0.3526    \n",
      "1423/1423 [==============================] - 1s     \n",
      "\n",
      "Accuracy is  0.801124385102\n",
      "F score is  0.832643406268\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(LSTM(64, return_sequences=False))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "model.fit(X_train, y_train, batch_size=32)\n",
    "model.save_weights('64_04_64_04.h5')\n",
    "predicted = model.predict_classes(X_test)\n",
    "print()\n",
    "print(\"Accuracy is \", accuracy_score(test.sex, predicted))\n",
    "print(\"F score is \", f1_score(test.sex, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 128 nodes, 0.6 dropout, 32 batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5791/5791 [==============================] - 39s - loss: 0.5390    \n",
      "Epoch 2/10\n",
      "5791/5791 [==============================] - 35s - loss: 0.4845    \n",
      "Epoch 3/10\n",
      "5791/5791 [==============================] - 36s - loss: 0.4610    \n",
      "Epoch 4/10\n",
      "5791/5791 [==============================] - 35s - loss: 0.4419    \n",
      "Epoch 5/10\n",
      "5791/5791 [==============================] - 34s - loss: 0.4293    \n",
      "Epoch 6/10\n",
      "5791/5791 [==============================] - 16s - loss: 0.4351    \n",
      "Epoch 7/10\n",
      "5791/5791 [==============================] - 10s - loss: 0.4232    \n",
      "Epoch 8/10\n",
      "5791/5791 [==============================] - 10s - loss: 0.4129    \n",
      "Epoch 9/10\n",
      "5791/5791 [==============================] - 10s - loss: 0.4023    \n",
      "Epoch 10/10\n",
      "5791/5791 [==============================] - 9s - loss: 0.3778     \n",
      "1376/1423 [============================>.] - ETA: 0s\n",
      "Accuracy is  0.801124385102\n",
      "F score is  0.852834113365\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, return_sequences=True, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(LSTM(128, return_sequences=False))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(2))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop')\n",
    "model.fit(X_train, y_train, batch_size=32)\n",
    "model.save_weights('128_06_128_06.h5')\n",
    "predicted = model.predict_classes(X_test)\n",
    "print()\n",
    "print(\"Accuracy is \", accuracy_score(test.sex, predicted))\n",
    "print(\"F score is \", f1_score(test.sex, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Best result for both metrics was shown by NN, which has 128 nodes per layer and dropout 0.4. Worst result is shown by NN with 512 nodes and dropout 0.2. Final results are shown below:\n",
    "\n",
    "128 nodes, 0.4 dropout, 16 batch size\n",
    "- Accuracy is  0.831342234715\n",
    "- F score is  0.865470852018\n",
    "\n",
    "128 nodes, 0.4 dropout, 32 batch size\n",
    "- Accuracy is  0.815179198876\n",
    "- F score is  0.861797162375\n",
    "\n",
    "128 nodes, 0.6 dropout, 32 batch size\n",
    "- Accuracy is  0.801124385102\n",
    "- F score is  0.852834113365\n",
    "\n",
    "256 nodes, 0.4 dropout, 16 batch size\n",
    "- Accuracy is  0.801124385102\n",
    "- F score is  0.845439650464\n",
    "\n",
    "64 nodes, 0.4 dropout, 32 batch size\n",
    "- Accuracy is  0.801124385102\n",
    "- F score is  0.832643406268\n",
    "\n",
    "512 nodes, 0.2 dropout, 32 batch size\n",
    "- Accuracy is  0.645115952214\n",
    "- F score is  0.776053215078\n",
    "\n",
    "Optimal parameters for NN are 128 nodes and 0.4 dropout. Increasing or decreasing number of nodes in layer decreases accuracy and F-score. Also, decreasing and increasing nodes is linearly correlated with time. Same applies for dropout. This reason might be that with higher dropout and smaller number of nodes NN is underfitting - too many nodes are ignored during regularisation or current number of nodes is not enough to build solid relationships. In opposite, NN is overfitting and cannot demonstrate high generalisation.\n",
    "<br><br>\n",
    "After all, when comparing methods of Naive Bayes classifier and LSTM NN, LSTM wins. This may be caused by ability of all RNN to remember processed objects, while Bayes classifier only uses aposterior probability. Very important difference between these two - Bayes classifier implies that there is not correlation within dataset, while LSTM can show good results even with correlation."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
